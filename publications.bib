
@article{Halabi2019,
	title = {Response {Times} for {Auditory} and {Vibrotactile} {Directional} {Cues} in {Different} {Immersive} {Displays}},
	volume = {35},
	issn = {1044-7318, 1532-7590},
	url = {https://www.tandfonline.com/doi/full/10.1080/10447318.2018.1555743},
	doi = {10.1080/10447318.2018.1555743},
	language = {en},
	number = {17},
	urldate = {2024-04-23},
	journal = {International Journal of Human–Computer Interaction},
	author = {Halabi, Osama and Bahameish, Mariam A. and Al-Naimi, Latefa T. and Al-Kaabi, Amna K.},
	month = oct,
	year = {2019},
	pages = {1578--1585},
	file = {Halabi2019.pdf:/Users/mariam/Library/CloudStorage/OneDrive-HamadbinKhalifaUniversity/Articles/Halabi2019.pdf:application/pdf},
}

@inproceedings{Bahameish2019,
	address = {Glasgow Scotland Uk},
	title = {Can {Changes} in {Heart} {Rate} {Variability} {Represented} in {Sound} be {Identified} by {Non}-{Medical} {Experts}?},
	isbn = {978-1-4503-5971-9},
	url = {https://dl.acm.org/doi/10.1145/3290607.3308456},
	doi = {10.1145/3290607.3308456},
	language = {en},
	urldate = {2024-04-23},
	booktitle = {Extended {Abstracts} of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Bahameish, Mariam},
	month = may,
	year = {2019},
	pages = {1--6},
}

@inproceedings{Bahameish2020,
	title = {Fundamental {Considerations} of {HRV} {Analysis} in the {Development} of {Real}-{Time} {Biofeedback} {Systems}},
	url = {https://ieeexplore.ieee.org/abstract/document/9344345/},
	urldate = {2024-04-23},
	booktitle = {2020 {Computing} in {Cardiology}},
	publisher = {IEEE},
	author = {Bahameish, Mariam and Stockman, Tony},
	year = {2020},
	pages = {1--4},
}

@article{Bahameish2024a,
	title = {Short-{Term} {Effects} of {Heart} {Rate} {Variability} {Biofeedback} on {Working} {Memory}},
	issn = {1090-0586, 1573-3270},
	url = {https://link.springer.com/10.1007/s10484-024-09624-7},
	doi = {10.1007/s10484-024-09624-7},
	language = {en},
	urldate = {2024-04-23},
	journal = {Applied Psychophysiology and Biofeedback},
	author = {Bahameish, Mariam and Stockman, Tony},
	month = feb,
	year = {2024},
}


@inproceedings{Bahameish2018,
	address = {Qatar National Convention Center (QNCC), Doha, Qatar,},
	title = {Scientific {Data} {Visualization} in an {Immersive} and {Collaborative} {Environment}},
	url = {https://www.qscience.com/content/papers/10.5339/qfarc.2018.ICTPD147},
	doi = {10.5339/qfarc.2018.ICTPD147},
	abstract = {Tremendous interest in visualizing massive datasets has promoted tiled-display wall systems that offer an immersive and collaborative environment with an extremely high-resolution. To achieve an efficient visualization, the rendering process should be parallelized and distributed among multiple nodes. The Data Observatory at Imperial College London has a unique setup consisting of 64 screens powered by 32 machines providing a resolution of over 130 megapixels. Various applications have been developed to achieve a high-performance visualization by implementing parallel rendering techniques and incorporating distributed rendering frameworks. ParaView is one such application that targets the visualization of scientific datasets by taking computing efficiency into consideration. The main objective of this project is to leverage the potential of the Data Observatory and ParaView regarding visualization by fostering data exploration, analysis, and collaboration through a scalable and high-performance approach. The primary concept is to configure ParaView on a distributed clustered network and associate the appropriate view for each screen by controlling ParaView's virtual camera. The interaction events with the application should be broadcasted to all connected nodes in the cluster to update their views accordingly. The major challenges of such implementations are synchronizing the rendering across all screens, maintaining data coherency, and managing data partitioning. Moreover, the project is aimed at evaluating the effectiveness of large display systems compared to typical desktop screens. This has been achieved by conducting two quantitative studies assessing the individual and collaborative task performance. The first task was designed to investigate the mental rotation of individuals by displaying a pair of a 3D model, as proposed by Shepard-Metzler, on the screen with different orientations. Then, the participant was asked if both models were the same or mirrored. This would lead to evaluate the individual task performance by studying the ability to recognize the orientation change in 3D objects. It consisted of two levels: easy and hard. For the easy level, the second model was rotated for a maximum angle of 30 on two axes. In contrast, the hard level had no limitation on the angle of rotation. The second task was developed specifically for ParaView to assess the collaboration aspect. The participants had to use the basic navigational operations to find hidden needles injected in a 3D brain model in 90 seconds. In both tasks, the time taken to complete the task and the correctness were measured in two environments: 1) the Data Observatory, and 2) a simple desktop screen. The average correct responses of the mental rotation task have been calculated for all participants. It has been shown that the number of correct answers in the Data Observatory is significantly higher than on the desktop screen despite the amount of rotation. The participants could better distinguish mirrored objects from similar ones in the Data Observatory with a percentage of 86.7\% and 73.3\% in easy and hard levels, respectively. However, on the typical desktop screen, participants correctly answered less than half of the hard level questions. This indicates immersive large display environments provides a better representation and depth perception of 3D objects. Thus, improving the task performance of visualizing 3D scenes in fields that require the ability to detect variations in the position or orientation. Overall, the average completion time of both displays in the easy task is relatively the same. In contrast, the participants required a longer time to complete the hard task in the Data Observatory. This could be because of the large display space, which occupies a wide visual field, thus providing an opportunity to the viewers to ponder and think about the right answer. In the collaborative search task, the participants found all the hidden needles within the time limitation in the Data Observatory. The fastest group completed the task in 36 seconds while the longest recorded time was around one minute and 12 seconds. However, on the desktop screen, all participants consumed the full 90 seconds. In the small screen environment, the mean of the correct responses is estimated as 55\%. The maximum number of needles found was 3 out of 4, which was achieved by only one group. To evaluate the overall efficiency of the Data Observatory, the one-way ANOVA test was used to find significant effects regarding the correctness of both tasks. The completion time was discarded from this analysis because of the differences in the tasks’ nature. The ANOVA revealed a significant impact of the display type in the number of correct responses, F1,48 = 10.517, p {\textless} 0.002. This indicates participants performed better in the Data Observatory in contrast to the simple desktop screen. Therefore, these results support the hypothesis of the effectiveness of large displays in improving the task performance and collaborative activities in terms of accuracy. The integration of both system solutions provides a novel approach to visualize the enormous amount of data generated from complex scientific computing. This adds great value to researchers and scientists to analyze, discuss, and discover the underlying behavior of certain phenomena.},
	language = {en},
	urldate = {2024-04-23},
	booktitle = {Qatar {Foundation} {Annual} {Research} {Conference} {Proceedings} {Volume} 2018 {Issue} 3},
	publisher = {Hamad bin Khalifa University Press (HBKU Press)},
	author = {Bahameish, Mariam Ali},
	year = {2018},
}

